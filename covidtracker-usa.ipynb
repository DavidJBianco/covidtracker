{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Tracker - USA\n",
    "\n",
    "This notebook provides basic information about trends in COVID-19 hospitalizations and deaths in the US at the country, state and county levels. The data is provided by the New York Times, who gathers it based on reports from state and local health agencies. More information on the NYT dataset is available [here](https://github.com/nytimes/covid-19-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use this Notebook\n",
    "The key is just to make sure that the NYT dataset is up-to-date.  The data is provided as a GitHub repository, which is included as a submodule of this repo.  Therefore, to update the data to the latest version, you simply need to issue the following command from within the top-level directory:\n",
    "\n",
    "> git pull --recurse --submodules\n",
    "\n",
    "If this is the first time you have run the notebook, you may first need to run the following command to properly set up the dataset:\n",
    "\n",
    "> git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.offline as po\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import requests\n",
    "\n",
    "import io\n",
    "\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from scipy import stats\n",
    "\n",
    "from huntlib.util import benfords\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters & Setup\n",
    "Some basic notebook config parameters here.  \n",
    "\n",
    "___ROLLING_AVERAGE_DAYS___ is the number of days upon which to compute rolling averages for the timeline view. The deafault is 7 days, so 1-week averages.\n",
    "\n",
    "___RECENT_DAYS___ is the number of days of history to consider when creating the activity heatmaps.  The default is 14 days, so the maps will reflect the most recent 2 weeks worth of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLLING_AVERAGE_DAYS = 7\n",
    "RECENT_DAYS = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Geographic Data\n",
    "First we load the data we'll use to create the maps.  These basically are just a set of coordinates for creating the outlines of the states and counties, tied to [FIPS location codes](https://en.wikipedia.org/wiki/FIPS_county_code).  The file we're using originally came from https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('geojson-counties-fips.json', 'r') as f:\n",
    "    counties = f.read()\n",
    "    \n",
    "counties_geojson = json.loads(counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the New York Times COVID-19 Data\n",
    "Now we'll load the county-level COVID-19 data into a DataFrame.  We'll also fix it up a little by converting types in some of the important columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_counties = pd.read_csv('covid-19-data/us-counties.csv', parse_dates=['date'])\n",
    "\n",
    "us_counties['fips'] = us_counties['fips'].astype('object')\n",
    "us_counties['county'] = us_counties['county'].astype('category')\n",
    "us_counties['state'] = us_counties['state'].astype('category')\n",
    "\n",
    "us_counties.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate Data\n",
    "The NYT dataset provides cumulative counts for each day, since the first case in the US. For our purposes, we're more interested in the per-day counts (i.e., the actual number of new cases or deaths for a single day).  \n",
    "\n",
    "In order to compute these from the cumulative counts, we first find all the unique _(state, county)_ pairs, then extract them each as temporary DataFrames.  Within each of these temporary frames, we can then subtract adjacent rows from each other to determine the delta, which is the count of new cases/deaths for each day.  \n",
    "\n",
    "Once we've done that, we concatenate all the temporary frames back into one big dataframe again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dfs = list()\n",
    "\n",
    "for state, county in tqdm(us_counties.groupby(['state', 'county']).groups.keys(), desc=\"Collating geographic info\"):\n",
    "    ldf = us_counties[(us_counties.state == state) & (us_counties.county == county)].copy()\n",
    "    ldf['daily_cases'] = ldf['cases'].diff().fillna(0).astype('int')\n",
    "    ldf['daily_deaths'] = ldf['deaths'].diff().fillna(0).astype('int')\n",
    "    local_dfs.append(ldf)\n",
    "    \n",
    "full_df = pd.concat(local_dfs, ignore_index=True).sort_values(by=['date', 'state', 'county']).reindex()\n",
    "\n",
    "full_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Functions\n",
    "Define some functions to create the visualizations we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_cumulative_summary(df, state=None, county=None):\n",
    "    if state:\n",
    "        df = df[df.state == state]\n",
    "        title = f\"{state} Cumulative Cases & Deaths\"\n",
    "        if county:\n",
    "            df = df[df.county == county]\n",
    "            title = f\"{county} County, {state} Cumulative Cases & Deaths\"\n",
    "    else:\n",
    "        title = \"US Cumulative Cases & Deaths\"\n",
    "        \n",
    "    cum_sum_df = df[['date', 'cases', 'deaths']].groupby('date').sum()\n",
    "    \n",
    "    fig = go.Figure(\n",
    "        data=go.Scatter(\n",
    "            x=cum_sum_df.index,\n",
    "            y=cum_sum_df['cases'],\n",
    "            mode='lines',\n",
    "            name='Total Cases'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=cum_sum_df.index,\n",
    "            y=cum_sum_df['deaths'],\n",
    "            mode='lines',\n",
    "            name='Deaths'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(df, column, state=None, county=None, anomaly_threshold=3, baseline_type='ra'):\n",
    "\n",
    "    \n",
    "    if state:\n",
    "        df = df[df.state == state]\n",
    "        title = f\"COVID-19 {column} vs {ROLLING_AVERAGE_DAYS} Day Average: {state}\"\n",
    "\n",
    "        if county and not county == '--':\n",
    "            df = df[df.county == county]\n",
    "            title = f\"COVID-19 {column} vs {ROLLING_AVERAGE_DAYS} Day Average: {county} County, {state}\"\n",
    "    else:\n",
    "        title = f\"COVID-19 {column} vs {ROLLING_AVERAGE_DAYS} Day Average: US\"\n",
    "\n",
    "            \n",
    "            \n",
    "    local_series = df[['date', column]].groupby('date').sum().sort_index()[column]\n",
    "    \n",
    "    fig = go.Figure(\n",
    "        data=go.Scatter(\n",
    "            x=local_series.index,\n",
    "            y=local_series,\n",
    "            mode='lines',\n",
    "            name=column\n",
    "        )\n",
    "    )\n",
    "\n",
    "    seasonal = STL(local_series, robust=True)\n",
    "    \n",
    "    seasonal = seasonal.fit()\n",
    "    \n",
    "    if baseline_type == 'trend' or baseline_type == 'trend_seasonal':\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=local_series.index,\n",
    "                y=seasonal.trend + seasonal.seasonal,\n",
    "                mode='lines',\n",
    "                marker_color='green',\n",
    "                name='Basline (Trend + Seasonal)'\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=local_series.index,\n",
    "                y=local_series.rolling(ROLLING_AVERAGE_DAYS).mean(),\n",
    "                mode='lines',\n",
    "                marker_color='green',\n",
    "                name=\"Baseline (Rolling Average)\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    anomalies = seasonal.resid[abs(seasonal.resid - seasonal.resid.mean()) >= (anomaly_threshold * seasonal.resid.std())]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=anomalies.index,\n",
    "            y=local_series.loc[anomalies.index],\n",
    "            mode='markers',\n",
    "            marker_symbol='x',\n",
    "            marker_color='red',\n",
    "            marker = dict(\n",
    "              size=10  \n",
    "            ),\n",
    "            name='Anomalies'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(df, geojson, column=None, locations='fips', height=1000, width=None, color_scale='viridis'):\n",
    "\n",
    "    fig = px.choropleth(\n",
    "        df,\n",
    "        geojson=geojson,\n",
    "        locations=locations,\n",
    "        color=column,\n",
    "        scope='usa',\n",
    "        hover_data=['county', 'fips', column],\n",
    "        height=height,\n",
    "        width=width,\n",
    "        color_continuous_scale=color_scale,\n",
    "        title=f\"{column} in Last {RECENT_DAYS} Days by County\"\n",
    "    )\n",
    "\n",
    "    fig.update_geos(fitbounds='locations')\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US\n",
    "First, show information about the country as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US Cumulative Cases & Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_daily_cumulative_summary(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US Timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timeseries(full_df, column='daily_cases')\n",
    "plot_timeseries(full_df, column='daily_deaths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Drill-Down\n",
    "In this section, you can use the widgets below to select a state (and optionally, a county) and examine cases and deaths in more detail.  \n",
    "\n",
    "The timeline views will be show either state- or county-level data, depending on your selections.  The heatmaps, however, only show the state-level views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = sorted(full_df.state.unique())\n",
    "counties = list(full_df.county.unique())\n",
    "counties.append('')\n",
    "counties = sorted(counties)\n",
    "\n",
    "\n",
    "widget_state_chooser = widgets.Dropdown(\n",
    "    options=states,\n",
    "    value='Virginia',\n",
    "    description=\"State: \"\n",
    ")\n",
    "\n",
    "widget_county_chooser = widgets.Dropdown(\n",
    "    options=counties,\n",
    "    value='',\n",
    "    description='County: '\n",
    ")\n",
    "\n",
    "@widgets.interact(state=widget_state_chooser, county=widget_county_chooser)\n",
    "def make_plots(state, county):\n",
    "    plot_timeseries(full_df, column='daily_cases', state=state, county=county)\n",
    "    plot_timeseries(full_df, column='daily_deaths', state=state, county=county)\n",
    "    \n",
    "    state_df = full_df[full_df.state == state]\n",
    "    start_time = state_df[-1:]['date'] - pd.DateOffset(RECENT_DAYS, 'D')\n",
    "\n",
    "    recent_df = state_df[state_df['date'] >= start_time.iloc[0]]\n",
    "    recent_df = recent_df.drop(['cases', 'deaths'], axis='columns')\n",
    "    recent_df = recent_df.groupby(['fips', 'county'], as_index=False).sum().dropna()\n",
    "    \n",
    "    plot_heatmap(recent_df, counties_geojson, column='daily_cases')\n",
    "    plot_heatmap(recent_df, counties_geojson, column='daily_deaths')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}